## 아파치 카프카 개요 및 설명

#### Data전송하는 Source Application VS Data 전송받는 Target Application

#### Before
1. 초기에는 간단한 단방향 통신
2. 어플리케이션이 많아지면서 데이터 전송 구조가 복잡해짐 
3. 데이터 전송 라인이 많아짐으로써 배포와 오류 대처에 문제 발생

#### Kafka 역할
아파치 카프카는 Source Application과 Target Application의 커플링을 약하게 한다.

Source Application은 Kafka로 데이터를 전송하고 Target Application은 Kafka에서 데이터를 가져온다.

Source Application에서 보내는 데이터 포맷은 거의 제한이 없다.(Json, tsv, avro ...)

Kafka는 데이터를 저장하는 Topic이란 개념이 있는데 일종의 큐라고 볼 수 있다.

Kafka Topic에 데이터를 저장하는 Producer와 데이터를 가져가는 Consumer가 있는데 Source Application을 Producer, Target Application을 Consumer로 볼 수 있다.

고가용성으로 서버에 이슈가 생기거나 전원이 내려간 상황에서도 데이터를 손실 없이 복구 할 수 있다.

낮은 지연과 높은 처리량으로 빅데이터 처리에 유용하다.


## 토픽이란?

카프카에는 다양한 형태의 데이터가 들어갈 수 있는데 이 때 데이터가 저장되는 곳을 토픽이라고한다

카프카에서의 토픽은 일종의 폴더라고 생각할 수 있고, 토픽을 여러개 생성 할 수 있다. 

프로듀서는 토픽에 데이터를 저장하고 컨슈머는 토픽에 저장된 데이터를 가져간다.

토픽은 이름을 가질 수 있고 목적에 따라 click_log, send_sms 등 명확한 용도를 기재할 수 있다.

하나의 토픽은 여러개의 파티션을 가질 수 있으며 이때 파티션은 Index 0번부터 시작된다.

하나의 파티션은 큐와 같이 내부에 데이터가 끝에서부터 차곡차곡(Index 0 시작)쌓이게 된다.

컨슈머는 가장 오래된 순서부터 데이터를 가져가게 된다(Index 0번부터 가져감)

`이 때 컨슈머가 데이터(record)를 가져가더라도 데이터는 삭제되지 않는다.`

카프카에서는 읽은 데이터를 토픽에서 삭제하지 않기 때문에

1. 컨슈머 그룹이 다르고

2. auto.offset.reset = earliest

로 설정된 경우, 새로운 컨슈머가 다시 0번부터 동일 데이터를 처리할 수 있다.

예를들어 동일한 데이터에 대해 1번 컨슈머 그룹에 속한 컨슈머가 로그를 ES에 저장하고, 2번 컨슈머 그룹에 속한 컨슈머가 Hadoop에 저장할 수 있다.

### 파티션이 두개 이상인 경우

데이터를 보낼 때 키를 지정할 수 있다.

만약 키를 지정하지 않으면(null) `Round-Robin` 으로 파티션이 지정된다.

키가 있고 기본 파티셔너를 사용할 경우, 키의 해시(Hash)를 구하고 특정 파티션에 할당

### 파티션 추가 생성

파티션은 늘릴수는 있지만 줄일 수는 없기 때문에 파티션을 늘리는 것은 신중해야한다

#### 파티션을 늘리는 이유

파티션을 늘리면 컨슈머 개수를 늘려서 데이터 분산 처리 가능

#### 파티션의 데이터(record) 삭제 시점

삭제 되는 타이밍은 옵션에 따라 다르다.

record가 저장되는 최대 시간과 크기를 지정할 수 있다

log.retention.ms : 최대 record 보존 시간  
log.retention.byte : 최대 record 보존 크기(byte)

## 카프카 프로듀서

#### Role

- Topic에 해당하는 메시지 생성
- 특정 Topic으로 데이터를 Publish
- 처리 실패/재시도


카프카 프로듀서, 컨슈머 사용을 위해선 아파치 카프카 라이브러리를 추가해야한다

브로커 버전과 클라이언트 버전의 하위 호환성이 완벽하게 지원되지 않으므로 버전에 주의한다.

[하위호환 참고 자료] : (https://blog.voidmainvoid.net/193, "하위호환 참고 자료")

```
//gradle
compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'

//maven
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>2.3.0</version>
</dependency>
```

#### 프로듀서 코드
```java
public class Producer{
	public static void main(String[] args) trhows IOException{
		// 프로듀서 설정
		Properties configs = new Properties();
		//bootstrap server 설정을 localhost의 카프카를 바라보도록 설정
		//브로커 오류를 대비해 카프카 브로커의 주소목록은 되도록이면 2개 이상의 ip와 port를 설정하도록 권장
		configs.put("bootstrap.servers", "localhost:9092");
		//key, value에 대해 String serializer로 직렬화 설정
		//Byte array, String, Integer Serialize 사용 가능
		//key는 메세지를 보내면 토픽의 파티션이 지정될 때 쓰인다.(hash) 설정안할 경우 round robin
		configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

		//kafka producer 인스턴스 생성
		KafkaProducer <String, String> producer = new KafkaProducer<>(configs);

		//토픽, key value 지정 가능. 아래 코드는 key 없이 click_log 토픽에 login이라는 value 전송
		ProducerRecord record = new ProduceerRecord<String, String>("click_log", "login");
		//key 지정하고싶을 경우 아래코드와 같이 전송
		//ProducerRecord record = new ProduceerRecord<String, String>("click_log", "key", "login");

		//카프카 메세지 전송
		producer.send(record);
		//프로듀서 종료
		producer.close();
	}
}
```

#### 주의사항

key를 이용해 partition을 구분해 데이터를 넣고 있을 때, 파티션이 늘어나게되면 key-partition 정합성이 깨지게 된다.

![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/1.PNG)

## Kafka 핵심요소 3가지(Broker, Replication, ISR)

Kafka Broker : 카프카가 설치되어 있는 서버 단위

오류를 대비해 보통 3개 이상의 Broker 사용 권장

만약 파티션이 1개이고 replication이 1인 topic이 존재하고, broker가 3대라면 

브로커 3대 중 1대에 해당 토픽의 정보(데이터)가 저장된다.

![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/2.PNG)
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/3.PNG)

Replication : 파티션의 복제

만약 replication이 1이라면 파티션이 1개만 존재하는것이고

replication이 2라면 파티션은 원본1개와 복제본 1개로 총 2개가 존재한다.
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/4.PNG)

마찬가지로 replication이 3이라면 파티션은 원본1개와 복제본 2개로 총 3개가 존재한다.

결국 여러대에 broker에 몇개의 복제본을 들고 있느냐가 replication이므로 replication은 broker 개수를 넘을 수 없다.

이때 원본을 가지고 있는 broker의 partition을 leader partition, 그 외의 복제본을 follower partition이라고 부른다.

위 Leader, Follower partition을 합쳐서 ISR(In Sync Replica)라고 부른다.
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/5.PNG)

#### Replication 사용 이유

Partition의 고가용성을 위해 사용한다

만약 브로커가 3개인 카프카에서 replication이 1이고 partition이 1인 토픽이 존재할 때

브로커가 어떠한 이유로 사용불가하게 된다면 해당 파티션은 더이상 복구할 수 없다.

만약 replication이 2라면 브로커 하나가 죽더라도 복제본(Follwer partition)이 존재하므로

복구가 가능하다. 이때 Follwer partition이 Leader partition이 된다.

#### Leader partition

Producer가 토픽의 파티션에 데이터를 전달할 때 전달받는 주체가 Leader partition이다

Producer에는 ack라는 상세옵션이 있는데 ack를 통해 고가용성을 유지할 수 있다.

#### ack 종류
- 0
  - Leader partition에 데이터를 전송하고 응답값을 받지 않는다. 따라서 Leader partition에 정상적으로 전송되었는지, 나머지 partition에 정상적으로 복제되었는지 알 수 없고 보장할 수 없다.
  - 속도는 빠르지만 데이터 유실 가능성이 있다.
- 1 
  - Leader partition이 데이터를 정상적으로 받았는지 응답값을 받는다
  - 나머지 partition에 정상적으로 복제되었는지 알 수 없다.
  - 복제가 안되었을 경우 Leader Partition에 장애가 발생하면 복구할 수 있는 데이터가 없으므로 ack 0과 마찬가지로 데이터 유실 가능성이 있다.
- all
  - follower partition에 복제가 잘 되었는지까지의 응답값을 받는다
  - 데이터 유실 없다.
  - 속도가 현저히 느리다.

#### Replication 개수
- replication이 많을수록 고가용성
- replication이 많을 수록 브로커의 리소스 사용량 증가
- 카프카에 들어오는 데이터 양과 retention date(저장시간)을 고려하여 replication 개수를 정한다
- 3개이상의 브로커를 사용할 경우 replication을 3으로 지정하는것을 추천






