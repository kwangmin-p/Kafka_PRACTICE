## 아파치 카프카 개요 및 설명

#### Data전송하는 Source Application VS Data 전송받는 Target Application

#### Before
1. 초기에는 간단한 단방향 통신
2. 어플리케이션이 많아지면서 데이터 전송 구조가 복잡해짐 
3. 데이터 전송 라인이 많아짐으로써 배포와 오류 대처에 문제 발생

#### Kafka 역할
아파치 카프카는 Source Application과 Target Application의 커플링을 약하게 한다.

Source Application은 Kafka로 데이터를 전송하고 Target Application은 Kafka에서 데이터를 가져온다.

Source Application에서 보내는 데이터 포맷은 거의 제한이 없다.(Json, tsv, avro ...)

Kafka는 데이터를 저장하는 Topic이란 개념이 있는데 일종의 큐라고 볼 수 있다.

Kafka Topic에 데이터를 저장하는 Producer와 데이터를 가져가는 Consumer가 있는데 Source Application을 Producer, Target Application을 Consumer로 볼 수 있다.

고가용성으로 서버에 이슈가 생기거나 전원이 내려간 상황에서도 데이터를 손실 없이 복구 할 수 있다.

낮은 지연과 높은 처리량으로 빅데이터 처리에 유용하다.


## 토픽이란?

카프카에는 다양한 형태의 데이터가 들어갈 수 있는데 이 때 데이터가 저장되는 곳을 토픽이라고한다

카프카에서의 토픽은 일종의 폴더라고 생각할 수 있고, 토픽을 여러개 생성 할 수 있다. 

프로듀서는 토픽에 데이터를 저장하고 컨슈머는 토픽에 저장된 데이터를 가져간다.

토픽은 이름을 가질 수 있고 목적에 따라 click_log, send_sms 등 명확한 용도를 기재할 수 있다.

하나의 토픽은 여러개의 파티션을 가질 수 있으며 이때 파티션은 Index 0번부터 시작된다.

하나의 파티션은 큐와 같이 내부에 데이터가 끝에서부터 차곡차곡(Index 0 시작)쌓이게 된다.

컨슈머는 가장 오래된 순서부터 데이터를 가져가게 된다(Index 0번부터 가져감)

`이 때 컨슈머가 데이터(record)를 가져가더라도 데이터는 삭제되지 않는다.`

카프카에서는 읽은 데이터를 토픽에서 삭제하지 않기 때문에

1. 컨슈머 그룹이 다르고

2. auto.offset.reset = earliest

로 설정된 경우, 새로운 컨슈머가 다시 0번부터 동일 데이터를 처리할 수 있다.

예를들어 동일한 데이터에 대해 1번 컨슈머 그룹에 속한 컨슈머가 로그를 ES에 저장하고, 2번 컨슈머 그룹에 속한 컨슈머가 Hadoop에 저장할 수 있다.

### 파티션이 두개 이상인 경우

데이터를 보낼 때 키를 지정할 수 있다.

만약 키를 지정하지 않으면(null) `Round-Robin` 으로 파티션이 지정된다.

키가 있고 기본 파티셔너를 사용할 경우, 키의 해시(Hash)를 구하고 특정 파티션에 할당

### 파티션 추가 생성

파티션은 늘릴수는 있지만 줄일 수는 없기 때문에 파티션을 늘리는 것은 신중해야한다

#### 파티션을 늘리는 이유

파티션을 늘리면 컨슈머 개수를 늘려서 데이터 분산 처리 가능

#### 파티션의 데이터(record) 삭제 시점

삭제 되는 타이밍은 옵션에 따라 다르다.

record가 저장되는 최대 시간과 크기를 지정할 수 있다

log.retention.ms : 최대 record 보존 시간  
log.retention.byte : 최대 record 보존 크기(byte)

## 카프카 프로듀서

#### Role

- Topic에 해당하는 메시지 생성
- 특정 Topic으로 데이터를 Publish
- 처리 실패/재시도


카프카 프로듀서, 컨슈머 사용을 위해선 아파치 카프카 라이브러리를 추가해야한다

브로커 버전과 클라이언트 버전의 하위 호환성이 완벽하게 지원되지 않으므로 버전에 주의한다.

[하위호환 참고 자료] : (https://blog.voidmainvoid.net/193, "하위호환 참고 자료")

```
//gradle
compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'

//maven
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>2.3.0</version>
</dependency>
```

#### 프로듀서 코드
```java
public class Producer{
	public static void main(String[] args) trhows IOException{
		// 프로듀서 설정
		Properties configs = new Properties();
		//bootstrap server 설정을 localhost의 카프카를 바라보도록 설정
		//브로커 오류를 대비해 카프카 브로커의 주소목록은 되도록이면 2개 이상의 ip와 port를 설정하도록 권장
		configs.put("bootstrap.servers", "localhost:9092");
		//key, value에 대해 String serializer로 직렬화 설정
		//Byte array, String, Integer Serialize 사용 가능
		//key는 메세지를 보내면 토픽의 파티션이 지정될 때 쓰인다.(hash) 설정안할 경우 round robin
		configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

		//kafka producer 인스턴스 생성
		KafkaProducer <String, String> producer = new KafkaProducer<>(configs);

		//토픽, key value 지정 가능. 아래 코드는 key 없이 click_log 토픽에 login이라는 value 전송
		ProducerRecord record = new ProduceerRecord<String, String>("click_log", "login");
		//key 지정하고싶을 경우 아래코드와 같이 전송
		//ProducerRecord record = new ProduceerRecord<String, String>("click_log", "key", "login");

		//카프카 메세지 전송
		producer.send(record);
		//프로듀서 종료
		producer.close();
	}
}
```

#### 주의사항

key를 이용해 partition을 구분해 데이터를 넣고 있을 때, 파티션이 늘어나게되면 key-partition 정합성이 깨지게 된다.

TODO. 이미지 올리기



