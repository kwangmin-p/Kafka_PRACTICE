## 아파치 카프카 개요 및 설명

#### Data전송하는 Source Application VS Data 전송받는 Target Application

#### Before
1. 초기에는 간단한 단방향 통신
2. 어플리케이션이 많아지면서 데이터 전송 구조가 복잡해짐 
3. 데이터 전송 라인이 많아짐으로써 배포와 오류 대처에 문제 발생

#### Kafka 역할
아파치 카프카는 Source Application과 Target Application의 커플링을 약하게 한다.

Source Application은 Kafka로 데이터를 전송하고 Target Application은 Kafka에서 데이터를 가져온다.

Source Application에서 보내는 데이터 포맷은 거의 제한이 없다.(Json, tsv, avro ...)

Kafka는 데이터를 저장하는 Topic이란 개념이 있는데 일종의 큐라고 볼 수 있다.

Kafka Topic에 데이터를 저장하는 Producer와 데이터를 가져가는 Consumer가 있는데 Source Application을 Producer, Target Application을 Consumer로 볼 수 있다.

고가용성으로 서버에 이슈가 생기거나 전원이 내려간 상황에서도 데이터를 손실 없이 복구 할 수 있다.

낮은 지연과 높은 처리량으로 빅데이터 처리에 유용하다.


## 토픽이란?

카프카에는 다양한 형태의 데이터가 들어갈 수 있는데 이 때 데이터가 저장되는 곳을 토픽이라고한다

카프카에서의 토픽은 일종의 폴더라고 생각할 수 있고, 토픽을 여러개 생성 할 수 있다. 

프로듀서는 토픽에 데이터를 저장하고 컨슈머는 토픽에 저장된 데이터를 가져간다.

토픽은 이름을 가질 수 있고 목적에 따라 click_log, send_sms 등 명확한 용도를 기재할 수 있다.

하나의 토픽은 여러개의 파티션을 가질 수 있으며 이때 파티션은 Index 0번부터 시작된다.

하나의 파티션은 큐와 같이 내부에 데이터가 끝에서부터 차곡차곡(Index 0 시작)쌓이게 된다.

컨슈머는 가장 오래된 순서부터 데이터를 가져가게 된다(Index 0번부터 가져감)

`이 때 컨슈머가 데이터(record)를 가져가더라도 데이터는 삭제되지 않는다.`

카프카에서는 읽은 데이터를 토픽에서 삭제하지 않기 때문에

1. 컨슈머 그룹이 다르고

2. auto.offset.reset = earliest

로 설정된 경우, 새로운 컨슈머가 다시 0번부터 동일 데이터를 처리할 수 있다.

예를들어 동일한 데이터에 대해 1번 컨슈머 그룹에 속한 컨슈머가 로그를 ES에 저장하고, 2번 컨슈머 그룹에 속한 컨슈머가 Hadoop에 저장할 수 있다.

### 파티션이 두개 이상인 경우

데이터를 보낼 때 키를 지정할 수 있다.

만약 키를 지정하지 않으면(null) `Round-Robin` 으로 파티션이 지정된다.

키가 있고 기본 파티셔너를 사용할 경우, 키의 해시(Hash)를 구하고 특정 파티션에 할당

### 파티션 추가 생성

파티션은 늘릴수는 있지만 줄일 수는 없기 때문에 파티션을 늘리는 것은 신중해야한다

#### 파티션을 늘리는 이유

파티션을 늘리면 컨슈머 개수를 늘려서 데이터 분산 처리 가능

#### 파티션의 데이터(record) 삭제 시점

삭제 되는 타이밍은 옵션에 따라 다르다.

record가 저장되는 최대 시간과 크기를 지정할 수 있다

log.retention.ms : 최대 record 보존 시간  
log.retention.byte : 최대 record 보존 크기(byte)

## 카프카 프로듀서

#### Role

- Topic에 해당하는 메시지 생성
- 특정 Topic으로 데이터를 Publish
- 처리 실패/재시도


카프카 프로듀서, 컨슈머 사용을 위해선 아파치 카프카 라이브러리를 추가해야한다

브로커 버전과 클라이언트 버전의 하위 호환성이 완벽하게 지원되지 않으므로 버전에 주의한다.

[하위호환 참고 자료] : (https://blog.voidmainvoid.net/193, "하위호환 참고 자료")

```
//gradle
compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'

//maven
<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>2.3.0</version>
</dependency>
```

#### 프로듀서 코드
```java
public class Producer{
	public static void main(String[] args) trhows IOException{
		// 프로듀서 설정
		Properties configs = new Properties();
		//bootstrap server 설정을 localhost의 카프카를 바라보도록 설정
		//브로커 오류를 대비해 카프카 브로커의 주소목록은 되도록이면 2개 이상의 ip와 port를 설정하도록 권장
		configs.put("bootstrap.servers", "localhost:9092");
		//key, value에 대해 String serializer로 직렬화 설정
		//Byte array, String, Integer Serialize 사용 가능
		//key는 메세지를 보내면 토픽의 파티션이 지정될 때 쓰인다.(hash) 설정안할 경우 round robin
		configs.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		configs.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

		//kafka producer 인스턴스 생성
		KafkaProducer <String, String> producer = new KafkaProducer<>(configs);

		//토픽, key value 지정 가능. 아래 코드는 key 없이 click_log 토픽에 login이라는 value 전송
		ProducerRecord record = new ProduceerRecord<String, String>("click_log", "login");
		//key 지정하고싶을 경우 아래코드와 같이 전송
		//ProducerRecord record = new ProduceerRecord<String, String>("click_log", "key", "login");

		//카프카 메세지 전송
		producer.send(record);
		//프로듀서 종료
		producer.close();
	}
}
```

#### 주의사항

key를 이용해 partition을 구분해 데이터를 넣고 있을 때, 파티션이 늘어나게되면 key-partition 정합성이 깨지게 된다.

![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/1.PNG)

## Kafka 핵심요소 3가지(Broker, Replication, ISR)

Kafka Broker : 카프카가 설치되어 있는 서버 단위

오류를 대비해 보통 3개 이상의 Broker 사용 권장

만약 파티션이 1개이고 replication이 1인 topic이 존재하고, broker가 3대라면 

브로커 3대 중 1대에 해당 토픽의 정보(데이터)가 저장된다.

![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/2.PNG)
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/3.PNG)

Replication : 파티션의 복제

만약 replication이 1이라면 파티션이 1개만 존재하는것이고

replication이 2라면 파티션은 원본1개와 복제본 1개로 총 2개가 존재한다.
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/4.PNG)

마찬가지로 replication이 3이라면 파티션은 원본1개와 복제본 2개로 총 3개가 존재한다.

결국 여러대에 broker에 몇개의 복제본을 들고 있느냐가 replication이므로 replication은 broker 개수를 넘을 수 없다.

이때 원본을 가지고 있는 broker의 partition을 leader partition, 그 외의 복제본을 follower partition이라고 부른다.

위 Leader, Follower partition을 합쳐서 ISR(In Sync Replica)라고 부른다.
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/5.PNG)

#### Replication 사용 이유

Partition의 고가용성을 위해 사용한다

만약 브로커가 3개인 카프카에서 replication이 1이고 partition이 1인 토픽이 존재할 때

브로커가 어떠한 이유로 사용불가하게 된다면 해당 파티션은 더이상 복구할 수 없다.

만약 replication이 2라면 브로커 하나가 죽더라도 복제본(Follwer partition)이 존재하므로

복구가 가능하다. 이때 Follwer partition이 Leader partition이 된다.

#### Leader partition

Producer가 토픽의 파티션에 데이터를 전달할 때 전달받는 주체가 Leader partition이다

Producer에는 ack라는 상세옵션이 있는데 ack를 통해 고가용성을 유지할 수 있다.

#### ack 종류
- 0
  - Leader partition에 데이터를 전송하고 응답값을 받지 않는다. 따라서 Leader partition에 정상적으로 전송되었는지, 나머지 partition에 정상적으로 복제되었는지 알 수 없고 보장할 수 없다.
  - 속도는 빠르지만 데이터 유실 가능성이 있다.
- 1 
  - Leader partition이 데이터를 정상적으로 받았는지 응답값을 받는다
  - 나머지 partition에 정상적으로 복제되었는지 알 수 없다.
  - 복제가 안되었을 경우 Leader Partition에 장애가 발생하면 복구할 수 있는 데이터가 없으므로 ack 0과 마찬가지로 데이터 유실 가능성이 있다.
- all
  - follower partition에 복제가 잘 되었는지까지의 응답값을 받는다
  - 데이터 유실 없다.
  - 속도가 현저히 느리다.

#### Replication 개수
- replication이 많을수록 고가용성
- replication이 많을 수록 브로커의 리소스 사용량 증가
- 카프카에 들어오는 데이터 양과 retention date(저장시간)을 고려하여 replication 개수를 정한다
- 3개이상의 브로커를 사용할 경우 replication을 3으로 지정하는것을 추천


## Kafka consumer

카프카에서는 consumer에서 데이터를 가져가도 사라지지 않는다.

Consumer가 토픽에 저장된 데이터를 가져오는것을 `Polling`이라고 한다

#### Consumer 역할
- Topic의 partition으로부터 데이터 polling
- Partition offset위치 기록(commit)
- Consumer group을 통해 병렬 처리

#### 컨슈머 코드
```java
public class Consumer{
	public static void main(String[] args){
		// java property 설정
		Properties configs = new Properties();
		configs.put("bootstrap.servers", "localhost:9092");
		// consumer group(group id) 지정
		configs.put("group.id","click_log_group");
		// key value 직렬화 설정
		configs.put("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
		configs.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");

		// consumer 인스턴스 생성
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);

		// 토픽 지정
		consumer.subscribe(Arrays.asList("clock_log"));
		//만약 특정 토픽의 전체 파티션이 아니라 일부 파티션의 데이터를 가져오고 싶은 경우 assign() 사용
		//키가 존재하는 경우, 아래 방식을 통해 데이터 순서를 보장할 수 있다
		// TopicPartition partition0 = new TopicPartition(topicName, 0);
		// TopicPartition partition1 = new TopicPartition(topicName, 1);
		// consumer.assign(Arrays.asList(partition0, partition1));
		while(true){
			// poll 파라미터로 지정한 시간만큼 데이터를 기다린다
			// 500ms 기다리고 이후 코드 실행
			// 데이터 없을 경우 빈 값의 records 반환
			ConsumerRecords<String, String> records = consumer.poll(500);
			for(ConsumerRecord<String, String> record: records){
				System.out.println(record.value());
			}
		}
	}
}
```

#### Consumer 동작 원리

Producer가 토픽에 데이터를 넣으면 여러 파티션에 round robin 혹은 키의 hash 값에 따라 파티션에 데이터가 저장된다

이때 토픽별, 파티션 별로 Offset number가 부여된다.

Offset을 통해 컨슈머가 데이터를 어느 지점까지 읽었는지 확인할 수 있다.

Consumer가 데이터를 읽으면 offset을 commit하고 이 정보를 카프카의 `__consumer_offset` 토픽에 저장한다.

만약 컨슈머가 장애로 인해 실행이 중지되었을 경우, `__consumer_offset`에 어디까지 읽었는지 알고있으므로

마지막으로 읽었던 위치부터 다시 복구하여 데이터를 처리할 수 있다. : `고가용성`

![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/6.PNG)

#### 컨슈머 개수

`Consumer 개수는 Partition 개수보다 적거나 같아야한다`

- 파티션이 2개, 컨슈머가 1개인 경우

한개의 컨슈머가 두개의 파티션의 데이터를 읽는다.
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/7.PNG)

- 파티션 2개, 컨슈머 2개인 경우

각 컨슈머가 하나씩의 파티션을 담당하여 데이터 처리
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/8.PNG)

- 파티션 2개, 컨슈머 3개인 경우

이미 파티션들이 각 컨슈머에 할당되었기 때문에 더이상 할당될 파티션이 없어 동작하지 않는다
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/9.PNG)


### 컨슈머 그룹이 다른 경우 컨슈머 동작

각기 다른 컨슈머 그룹에 속한 컨슈머는 다른 컨슈머 그룹에 영향을 미치지 않는다

Elastic search에 데이터를 저장하는 컨슈머 그룹과 Hadoop에 데이터를 저장하는 컨슈머 그룹이 있다고 가정
![](https://github.com/kwangmin-park/Kafka_PRACTICE/blob/master/image/10.PNG)

`__consumer_offset` 에는 컨슈머 그룹별로, 토픽별로 offset을 나누어 저장하기 때문에

Elastic 컨슈머 그룹이 Hadoop 컨슈머 그룹에 영향을 미치지 않는다

카프카의 이런 특성으로, 하나의 토픽으로 들어온 데이터를 다양한 역할을 하는 컨슈머가 각자 원하는 방식으로 처리할 수 있다


## Partitioner

Producer가 데이터를 전송하면 partitioner를 통해 브로커로 데이터가 전송된다

Partitioner는 record에 포함된 메시지 키 혹은 값에 따라 데이터를 토픽의 `어떤 partition에 저장할지 결정`

Producer를 사용할 때 partitioner를 따로 설정하지 않으면 default로 UniformStickyPartitioner로 설정된다

#### UniformStickyPartitioner 동작 원리

- 메시지 키가 있는 경우

키의 hash값을 기준으로 파티션 지정

동일한 메세지 키는 항상 동일한 hash 값을 생성하기 때문에 항상 동일한 partition에 저장되는 것을 보장한다

동일한 키를 가진 데이터는 동일한 파티션에 들어가기 때문에 순서를 보장하는 장점이 있다

- 메시지 키가 없는 경우

Round Robin 으로 파티션에 들어간다

일반적인 Round Robin과는 달리 프로듀서에서 배치로 모을 수 있는 최대한의 레코드를 모아서

한번에 파티션으로 데이터를 보낸다.

#### Consumer Lag

Consumer Lag : Producer가 넣은 data offset과 Consumer 가 읽는 data offset 간의 차이

Partition마다 offset을 가지고 있기 때문에 consumer lag은 토픽 개수와 같다

만약 컨슈머 그룹이 1개이고 파티션이 2개인 토픽이라면 lag은 2개가 측정된다.

여러개의 lag이 존재할 때 그 중 높은 lag을 records-lag-max 라고 칭한다.

## Kafka Lag monitoring application `Burrow`

1. 멀티 카프카 클러스터 지원
2. Sliding window를 통한 Consumer Status(ERROR, WARNING, OK) 확인
3. HTTP API 제공


## 카프카, 레빗엠큐, 레디스 큐 차이점

#### 메시징 플랫폼 종류 및 특징
1. 메시지 브로커(레디스 큐, 레빗엠 큐)
- 메시지 브로커는 이벤트 브로커 역할 불가
- 메시징 플랫폼, 인증 플랫폼
- 메시지를 받아서 적절히 처리하고 나면 즉시 또는 짧은 시간내에 `삭제`

2. 이벤트 브로커(카프카, AWS의 키네시스)
- 이벤트 브로커는 메시지 브로커 역할 가능
- 이벤트 또는 메시지라고 불리는 레코드를 딱 하나만 저장하고 인덱스(Offset)를 통해 개별 액세스를 관리한다
- 업무상 필요한 시간 동안 이벤트를 `보존`할 수 있다
- 데이터를 삭제하지 않으므로 장애가 발생했을 때 장애가 발생한 지점부터 재처리 가능
- 많은 양의 실시간 스트림 데이터를 효과적으로 처리 가능(삭제 비용이 없기 때문)
- MSA 의 네트워크 기능


## 3개의 카프카 브로커로 이루어진 클러스터 실습

#### 실습 요구 사항
- 테스트 용도이므로 프리티어인 EC2(t2.micro 1개 CPU 1G-RAM) 3대 발급 (EC2 발급시 인스턴스 개수를 3개로 설정)
- 3개의 인스턴스 설정해야하므로 멀티 터미널을 위해 iterm2 설치 후 [cmd+shit+d] 를 눌러 화면을 나누고 [cmd+shit+i] 를 눌러 동시 입력으로 설정 간편화
- iterm2 설치 참고 : https://www.youtube.com/watch?v=mpea_CtJWyI&t=1s

#### 환경 설정 및 설치 과정
참고 자료 : https://blog.voidmainvoid.net/325

#### 주키퍼 설치
- 주키퍼 : 카프카의 정보 저장
1. zookeeper 설치 : wget https://downloads.apache.org/zookeeper/zookeeper-3.6.0/apache-zookeeper-3.6.0-bin.tar.gz
2. zookeeper 압축 해제 :
  1. tar xvf
  2. tar xvf apache-zookeeper-3.6.0-bin.tar.gz
3. zookeeper 앙상블 구축 위한 서버 설정 : 
  1. vi zoo.cfg
  2. tickTime=2000  
     dataDir=/var/lib/zookeeper  
     clientPort=2181  
     initLimit=20  
     syncLimit=5  
     server.1=test-broker01:2888:3888  
     server.2=test-broker02:2888:3888  
     server.3=test-broker03:2888:3888  
4. /etc/hosts 설정 : vi /etc/hosts
  - 자기 자신의 host는 0.0.0.0으로 설정하고 나머지는 ip로 할당되게 설정
  - test-broker01인 경우
  - 0.0.0.0 test-broker01  
    14.252.123.4 test-broker02  
    55.231.124.1 test-broker03
5. 방화벽 설정 : AWS security group의 Inboud rule, Outbound rule 설정
  - 주키퍼는 2181, 2888, 3888 포트를 사용하므로 세 포트에 대해 anywhere 조건으로 open
  - Inbound 설정 시 Type: Custom TCP, Port range: 3888, Source: Anywhere 와 같이 설정
  - 카프카 통신을 위해 9092 포트도 open
6. 각 서버 주키퍼 실행 : ./zkServer.sh start
  - Starting zookeeper ... STARTED < 메세지 확인
7. 방화벽 설정이 정상이고 주키퍼가 정상적으로 실행되는지 확인
  - 로컬 컴퓨터에서 AWS의 주키퍼에 연결 확인
  1. bin ./zkCli -server 54.180.98.4:2181
  2. ls /
  3. get /
  4. [zk: 54.180.98.4:2181(CONNECTED) 2] < 메세지 확인

#### 카프카 설치
1. 카프카 압축 파일 다운로드 : wget https://archive.apache.org/dist/kafka/2.1.0/kafka_2.11-2.1.0.tgz
2. 카프카 압축 해제 : tar xvf kafka_2.11-2.1.0.tgz
3. 경로 이동
  1. ls
  2. cd kafka_2.11-2.1.0/
  3. cd config
4. 카프카 브로커 서버 설정 : vi server.properties
  1. broker.id 를 각 카프카 브로커 별로 다른 숫자로 설정(0, 1, 2 ...)
  2. listener 설정 : listeners=:9092
  3. advertise listener 설정 : advertiesed.listeners=test-broker01:9092
  4. zookeep의 hostname, port 설정 : zookeeper.connect=test-broker01:2181,test-broker02:2181,test-broker03/test:2181
5. 카프카 실행 : ./kafka-server-start.sh ../config/server.properties
6. 카프카 테스트
  1. 로컬에서 'test_log' 토픽 생성 : bin ./kafka-topics --create --zooeeper test-broker01:2181,test-broker02:2181,test-broker03:2181/test --replication-factor 1 --partitions 1 --topic test_lig
  2. console-producer로 'test_log' 토픽에 데이터 삽입 : bin ./kafka-console-producer --broker-list 54.180.98.4:9092,15.163.97.6:9092,54.180.93.146:9092 --topic test_log
  3. 다른 커맨드 창에서 'test_log' 토픽 consume으로 데이터 확인 : ./kafka-console-consumer --bootstrap-server 54.180.98.4:9092,15.163.97.6:9092,54.180.93.146:9092 --topic test_log --from-beginning












